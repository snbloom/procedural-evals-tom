{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanishk/opt/anaconda3/envs/marple/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<|endoftext|>\n",
      "50256\n",
      "{'input_ids': tensor([[7454, 2402,  257,  640]]), 'attention_mask': tensor([[1, 1, 1, 1]])}\n",
      "{'input_ids': tensor([[50256,  7454,  2402,   257,   640]]), 'attention_mask': tensor([[1, 1, 1, 1, 1]])}\n"
     ]
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"roneneldan/TinyStories-28M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n",
    "print(tokenizer.bos_token)\n",
    "print(tokenizer.bos_token_id)\n",
    "\n",
    "sentence = \"Once upon a time\"\n",
    "input = tokenizer(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "print(input)\n",
    "\n",
    "# from tokenizers.processors import TemplateProcessing\n",
    "# tokenizer.post_processor = TemplateProcessing(\n",
    "#     single=f\"{tokenizer.bos_token} $A\",\n",
    "#     special_tokens=[(f\"{tokenizer.bos_token}\", tokenizer.bos_token_id)],\n",
    "# )\n",
    "\n",
    "sentence = tokenizer.bos_token + sentence\n",
    "\n",
    "input = tokenizer(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "print(input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_ppl(sentence, bos=True):\n",
    "    # Tokenize the sentence\n",
    "    loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    input = tokenizer(\n",
    "            sentence,\n",
    "            add_special_tokens=True,\n",
    "            padding=False,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(device)\n",
    "    input_ids = input[\"input_ids\"].to(device)\n",
    "    print(input_ids)\n",
    "    attn_mask = input[\"attention_mask\"].to(device)\n",
    "    if bos:\n",
    "        bos_tokens_tensor = torch.tensor([[tokenizer.bos_token_id]]).to(device)\n",
    "        input_ids = torch.cat([bos_tokens_tensor, input_ids], dim=1).to(device)\n",
    "        attn_mask = torch.cat(\n",
    "                        [torch.ones(bos_tokens_tensor.size(), dtype=torch.int64).to(device), attn_mask], dim=1\n",
    "                    )\n",
    "    \n",
    "    # Get log probabilities from the model\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask=attn_mask,  labels=input_ids).logits\n",
    "        \n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    shift_labels = input_ids[..., 1:].contiguous()\n",
    "    # shift_attention_mask_batch = attn_mask[..., 1:].contiguous()\n",
    "    ce_loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    # ce_loss = loss_fct(shift_logits.transpose(1, 2), shift_labels)\n",
    "    perplexities = torch.exp(ce_loss)\n",
    "    token_ids = shift_labels.cpu().numpy().tolist()[0]\n",
    "    perplexities = perplexities.cpu().numpy().tolist()\n",
    "    return token_ids, perplexities \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 7454,  2402,   257,   640,    11,   612,   373,   257,  8030,  6512,\n",
      "          3706,  5811,    13,  5811,  5615,  1474,   257,  1263, 19516,    13,\n",
      "          3887,  1110,    11,  5811]])\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m token_ids, ppl \u001b[39m=\u001b[39m get_sentence_ppl(sentence, bos\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m      3\u001b[0m \u001b[39m# print(result, np.mean(list(result.values())[1:]))\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[39m# print tokenwise_ppl\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m token_ids \u001b[39m=\u001b[39m token_ids\u001b[39m.\u001b[39;49mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtolist()[\u001b[39m0\u001b[39m]\n\u001b[1;32m      6\u001b[0m ppl \u001b[39m=\u001b[39m ppl\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtolist()\n\u001b[1;32m      7\u001b[0m \u001b[39mfor\u001b[39;00m token_id, ppl \u001b[39min\u001b[39;00m \u001b[39mzip\u001b[39m(token_ids, ppl):\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "sentence = \"Once upon a time, there was a friendly bird named Bob. Bob lived near a big cliff. Every day, Bob\"\n",
    "token_ids, ppl = get_sentence_ppl(sentence, bos=True)\n",
    "# print(result, np.mean(list(result.values())[1:]))\n",
    "# print tokenwise_ppl\n",
    "token_ids = token_ids.cpu().numpy().tolist()[0]\n",
    "ppl = ppl.cpu().numpy().tolist()\n",
    "for token_id, ppl in zip(token_ids, ppl):\n",
    "    print(tokenizer.decode(token_id), ppl)\n",
    "print(np.mean(ppl))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'perplexities': [2.667530059814453], 'mean_perplexity': 2.667530059814453}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "results = perplexity.compute(model_id='roneneldan/TinyStories-28M',\n",
    "                             add_start_token=False,\n",
    "                             predictions=[sentence])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tinystories\n",
    "path = f'../tinystories_words/tinystories_rows_gpt4.txt'\n",
    "tinystories = []\n",
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tinystories.append(line.strip())\n",
    "path = f'../tinystories_words/tinystories_rows_gpt4.txt'\n",
    "tinystories_gpt4 = []\n",
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tinystories_gpt4.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One day, a little boy named Tim was playing outside. He saw a big, scary dog near the post. The dog had a loud bark and sharp teeth. Tim felt worry in his tummy. He did not want the dog to come near him.Tim's mom saw him worry and came outside. She saw the scary dog too. Tim's mom told him not to worry. She said they would scare the dog away together. Tim felt a little better.Tim and his mom made loud noises and waved their arms. The scary dog ran away from the post. Tim was not worry anymore. He was happy that his mom helped him. They went inside to have a snack and play.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:00<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'perplexities': [3.483666181564331], 'mean_perplexity': 3.483666181564331}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get ppl of a random story\n",
    "import random\n",
    "random_story = random.choice(tinystories)\n",
    "print(random_story)\n",
    "results = perplexity.compute(model_id='roneneldan/TinyStories-28M',\n",
    "                                add_start_token=False,\n",
    "                                predictions=[random_story])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'shape'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[145], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# get token-level ppl of a random story\u001b[39;00m\n\u001b[1;32m      2\u001b[0m token_ids, ppl \u001b[39m=\u001b[39m get_sentence_ppl(random_story, bos\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m----> 3\u001b[0m \u001b[39mprint\u001b[39m(token_ids\u001b[39m.\u001b[39;49mshape)\n\u001b[1;32m      4\u001b[0m token_ids \u001b[39m=\u001b[39m token_ids\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy()\u001b[39m.\u001b[39mtolist()[\u001b[39m0\u001b[39m]\n\u001b[1;32m      5\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(token_id))\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'shape'"
     ]
    }
   ],
   "source": [
    "# get token-level ppl of a random story\n",
    "token_ids, ppl = get_sentence_ppl(random_story, bos=True)\n",
    "print(token_ids.shape)\n",
    "token_ids = token_ids.cpu().numpy().tolist()[0]\n",
    "print(len(token_id))\n",
    "ppl = ppl.cpu().numpy().tolist()\n",
    "for token_id, ppl in zip(token_ids, ppl):\n",
    "    print(tokenizer.decode(token_id), ppl)\n",
    "print(np.mean(ppl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tb and fb stories\n",
    "tb_stories = []\n",
    "fb_stories = []\n",
    "pos_tb_stories = []\n",
    "pos_fb_stories = []\n",
    "neg_tb_stories = []\n",
    "neg_fb_stories = []\n",
    "\n",
    "tb_cond_file  = f'../../data/conditions/tinytom-v3/0_forward_belief_true_belief/corrected.txt'\n",
    "fb_cond_file  = f'../../data/conditions/tinytom-v3/0_forward_belief_false_belief/corrected.txt'\n",
    "with open(tb_cond_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l, line in enumerate(lines):\n",
    "        tb_stories.append(line.strip())\n",
    "\n",
    "with open(fb_cond_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l, line in enumerate(lines):        \n",
    "        fb_stories.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once 3786918.75\n",
      " upon 1.0253037214279175\n",
      " a 1.0000678300857544\n",
      " time 1.0001612901687622\n",
      ", 1.0017625093460083\n",
      " in 26.137815475463867\n",
      " a 1.0432683229446411\n",
      " lovely 255.73524475097656\n",
      " park 147.6114044189453\n",
      " full 1578.48095703125\n",
      " of 1.004035472869873\n",
      " pretty 59.270225524902344\n",
      " flowers 1.1265602111816406\n",
      ", 6.635289192199707\n",
      " there 1.136163353919983\n",
      " was 1.290573239326477\n",
      " a 1.004797101020813\n",
      " little 1.7714539766311646\n",
      " girl 1.9726015329360962\n",
      " named 1.0066407918930054\n",
      " Queen 16705913.0\n",
      "ie 1.6073189973831177\n",
      ". 1.0317797660827637\n",
      " She 6.450061798095703\n",
      " needed 1701482.75\n",
      " a 11.8333740234375\n",
      " green 9422.484375\n",
      " leaf 5.010408401489258\n",
      " for 4.829154014587402\n",
      " her 1.0386905670166016\n",
      " art 878.48779296875\n",
      " project 2.2610509395599365\n",
      ". 1.047688364982605\n",
      " She 4.079145908355713\n",
      " spotted 51498.6015625\n",
      " a 1.6199395656585693\n",
      " leaf 25.733139038085938\n",
      " that 9.338224411010742\n",
      " was 1.553296446800232\n",
      " very 19.732328414916992\n",
      " green 13.203532218933105\n",
      " and 3.0927369594573975\n",
      " fresh 5605.99462890625\n",
      ". 1.009093999862671\n",
      " As 555.260009765625\n",
      " Queen 25.05815887451172\n",
      "ie 1.0032645463943481\n",
      " explored 3006647.0\n",
      " the 1.2598310708999634\n",
      " big 17194.716796875\n",
      " park 3.0037059783935547\n",
      ", 1.037485122680664\n",
      " the 482.73583984375\n",
      " sun 6.047307968139648\n",
      " smiled 368.815673828125\n",
      " brighter 89237.3125\n",
      " and 1.245975375175476\n",
      " brighter 5.542998313903809\n",
      ". 1.2051496505737305\n",
      " The 18.64461898803711\n",
      " little 36.90946578979492\n",
      " leaf 7.997826099395752\n",
      " got 1497.500244140625\n",
      " all 191.04339599609375\n",
      " warm 255.961181640625\n",
      " and 1.1251946687698364\n",
      " dry 4.424380302429199\n",
      " from 63.586273193359375\n",
      " the 1.073927402496338\n",
      " sun 1.566879391670227\n",
      "'s 6.843565940856934\n",
      " happy 63604.83984375\n",
      " heat 129.6708526611328\n",
      ". 1.0552184581756592\n",
      " Queen 1.0616527795791626\n",
      "ie 1.0021116733551025\n",
      " sees 112632016.0\n",
      " the 2.3846278190612793\n",
      " leaf 1.5700091123580933\n",
      " dried 403027.1875\n",
      " up 1.1155980825424194\n",
      " when 11445.033203125\n",
      " she 5.273295879364014\n",
      " returns 60749.78125\n",
      " to 3.9617679119110107\n",
      " it 230.74887084960938\n",
      ". 1.315391182899475\n",
      " Queen 13.292914390563965\n",
      "ie 1.0021352767944336\n",
      " believes 1626.76416015625\n",
      " the 14.61481761932373\n",
      " leaf 1.119633436203003\n",
      " is 5.029558181762695\n",
      "5.029558181762695\n"
     ]
    }
   ],
   "source": [
    "random_story = random.choice(tb_stories)\n",
    "token_ids, ppl = get_sentence_ppl(random_story, bos=True)\n",
    "token_ids = token_ids.cpu().numpy().tolist()[0]\n",
    "ppl = ppl.cpu().numpy().tolist()\n",
    "for token_id, ppl in zip(token_ids, ppl):\n",
    "    print(tokenizer.decode(token_id), ppl)\n",
    "print(np.mean(ppl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
