{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kanishk/opt/anaconda3/envs/marple/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import datasets\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model_id = \"roneneldan/TinyStories-28M\"\n",
    "model = AutoModelForCausalLM.from_pretrained(model_id)\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_id)\n",
    "\n",
    "tokenizer.pad_token = tokenizer.eos_token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_ppl(sentence, bos=False):\n",
    "    # Tokenize the sentence\n",
    "    loss_fct = CrossEntropyLoss(reduction=\"none\")\n",
    "\n",
    "    input = tokenizer(\n",
    "            sentence,\n",
    "            add_special_tokens=False,\n",
    "            padding=True,\n",
    "            truncation=True,\n",
    "            max_length=512,\n",
    "            return_tensors=\"pt\",\n",
    "            return_attention_mask=True,\n",
    "        ).to(device)\n",
    "    input_ids = input[\"input_ids\"].to(device)\n",
    "    attn_mask = input[\"attention_mask\"].to(device)\n",
    "    if bos:\n",
    "        bos_tokens_tensor = torch.tensor([[tokenizer.bos_token_id]]).to(device)\n",
    "        input_ids = torch.cat([bos_tokens_tensor, input_ids], dim=1).to(device)\n",
    "        attn_mask = torch.cat(\n",
    "                        [torch.ones(bos_tokens_tensor.size(), dtype=torch.int64).to(device), attn_mask], dim=1\n",
    "                    )\n",
    "    \n",
    "    # Get log probabilities from the model\n",
    "    with torch.no_grad():\n",
    "        logits = model(input_ids, attention_mask=attn_mask,  labels=input_ids).logits\n",
    "        \n",
    "    shift_logits = logits[..., :-1, :].contiguous()\n",
    "    shift_labels = input_ids[..., 1:].contiguous()\n",
    "    # shift_attention_mask_batch = attn_mask[..., 1:].contiguous()\n",
    "    ce_loss = loss_fct(shift_logits.view(-1, shift_logits.size(-1)), shift_labels.view(-1))\n",
    "    # ce_loss = loss_fct(shift_logits.transpose(1, 2), shift_labels)\n",
    "    perplexities = torch.exp(ce_loss)\n",
    "    return shift_labels, perplexities\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once 3786911.5\n",
      " upon 1.0253034830093384\n",
      " a 1.0000678300857544\n",
      " time 1.0001612901687622\n",
      ", 1.0017625093460083\n",
      " there 1.0782173871994019\n",
      " was 1.0065215826034546\n",
      " a 1.0115015506744385\n",
      " friendly 478.8094787597656\n",
      " bird 105.92422485351562\n",
      " named 1.4727593660354614\n",
      " Bob 5.523642539978027\n",
      ". 1.6974177360534668\n",
      " Bob 1.0217628479003906\n",
      " lived 2.947664737701416\n",
      " near 20.135814666748047\n",
      " a 1.1660058498382568\n",
      " big 1.3090853691101074\n",
      " cliff 6.568779945373535\n",
      ". 1.0390673875808716\n",
      " Every 5.105368614196777\n",
      " day 1.0388258695602417\n",
      ", 1.0028589963912964\n",
      " Bob 2.163477897644043\n",
      "2.163477897644043\n"
     ]
    }
   ],
   "source": [
    "sentence = \"Once upon a time, there was a friendly bird named Bob. Bob lived near a big cliff. Every day, Bob\"\n",
    "token_ids, ppl = get_sentence_ppl(sentence, bos=True)\n",
    "# print(result, np.mean(list(result.values())[1:]))\n",
    "# print tokenwise_ppl\n",
    "token_ids = token_ids.cpu().numpy().tolist()[0]\n",
    "ppl = ppl.cpu().numpy().tolist()\n",
    "for token_id, ppl in zip(token_ids, ppl):\n",
    "    print(tokenizer.decode(token_id), ppl)\n",
    "print(np.mean(ppl))\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:00<00:00,  7.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'perplexities': [2.667530059814453], 'mean_perplexity': 2.667530059814453}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import evaluate\n",
    "perplexity = evaluate.load(\"perplexity\", module_type=\"metric\")\n",
    "results = perplexity.compute(model_id='roneneldan/TinyStories-28M',\n",
    "                             add_start_token=False,\n",
    "                             predictions=[sentence])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load tinystories\n",
    "path = f'../tinystories_words/tinystories_rows_gpt4.txt'\n",
    "tinystories = []\n",
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tinystories.append(line.strip())\n",
    "path = f'../tinystories_words/tinystories_rows_gpt4.txt'\n",
    "tinystories_gpt4 = []\n",
    "with open(path, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines:\n",
    "        tinystories_gpt4.append(line.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once upon a time, there was a big pumpkin. It was hot outside, and the pumpkin was sad. It wanted to be cool like the other pumpkins in the garden. The pumpkin saw a bird sitting on a tree branch and asked, \"Can you teach me how to be cool like the other pumpkins?\"The bird said, \"I can teach you how to make a big shade. Then you will be cool like the other pumpkins.\" The pumpkin was happy to learn from the bird. So, they worked together to make a big shade using leaves and sticks.But then, a strong wind came and blew the shade away. The pumpkin was sad again. The bird told the pumpkin, \"It's okay. Sometimes things don't work out the way we want them to. The important thing is to keep trying and never give up.\"The pumpkin learned to be strong and keep trying, even when things were hard. And soon, the weather changed, and the pumpkin was cool and happy like the other pumpkins. The moral of the story is to never give up and keep trying, even when things are tough.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using pad_token, but it is not set yet.\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'perplexities': [2.9053306579589844], 'mean_perplexity': 2.9053306579589844}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# get ppl of a random story\n",
    "import random\n",
    "random_story = random.choice(tinystories)\n",
    "print(random_story)\n",
    "results = perplexity.compute(model_id='roneneldan/TinyStories-28M',\n",
    "                                add_start_token=False,\n",
    "                                predictions=[random_story])\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once 3786918.75\n",
      " upon 1.0253037214279175\n",
      " a 1.0000678300857544\n",
      " time 1.0001612901687622\n",
      ", 1.0017625093460083\n",
      " there 1.0782172679901123\n",
      " was 1.0065215826034546\n",
      " a 1.0115015506744385\n",
      " big 10.045510292053223\n",
      " pumpkin 543.5086669921875\n",
      ". 1.3449971675872803\n",
      " It 1.2260874509811401\n",
      " was 1.0084749460220337\n",
      " hot 2340.401123046875\n",
      " outside 1.0120939016342163\n",
      ", 1.9742428064346313\n",
      " and 1.8300126791000366\n",
      " the 1.0309021472930908\n",
      " pumpkin 1.0310642719268799\n",
      " was 1.666839838027954\n",
      " sad 11.699323654174805\n",
      ". 1.2397280931472778\n",
      " It 1.191320776939392\n",
      " wanted 1.0967988967895508\n",
      " to 1.0277469158172607\n",
      " be 2.52840518951416\n",
      " cool 4.993949890136719\n",
      " like 7.950096130371094\n",
      " the 1.0992697477340698\n",
      " other 1.086223840713501\n",
      " pump 1.0618982315063477\n",
      "kins 1.250278353691101\n",
      " in 14.077720642089844\n",
      " the 1.0086685419082642\n",
      " garden 4.384374141693115\n",
      ". 1.0216915607452393\n",
      " The 5.038606643676758\n",
      " pumpkin 5.195713043212891\n",
      " saw 16.96390151977539\n",
      " a 1.251333475112915\n",
      " bird 54.263065338134766\n",
      " sitting 32.592655181884766\n",
      " on 1.13992440700531\n",
      " a 1.1144988536834717\n",
      " tree 2.1602606773376465\n",
      " branch 3.0094053745269775\n",
      " and 4.511900424957275\n",
      " asked 1.8116984367370605\n",
      ", 1.1546802520751953\n",
      " \" 1.0006272792816162\n",
      "Can 2.0059444904327393\n",
      " you 1.0425246953964233\n",
      " teach 33.86040496826172\n",
      " me 1.000152349472046\n",
      " how 1.0588732957839966\n",
      " to 1.000600814819336\n",
      " be 1.666153907775879\n",
      " cool 1.008812427520752\n",
      " like 1.071537971496582\n",
      " the 5.365480422973633\n",
      " other 1.0299931764602661\n",
      " pump 1.0032879114151\n",
      "kins 1.0052659511566162\n",
      "?\" 1.026468276977539\n",
      "The 13898.19921875\n",
      " bird 1.002055048942566\n",
      " said 1.3552064895629883\n",
      ", 1.0016241073608398\n",
      " \" 1.0000298023223877\n",
      "I 6.648423194885254\n",
      " can 1.4614169597625732\n",
      " teach 11.848616600036621\n",
      " you 1.0002750158309937\n",
      " how 16.525646209716797\n",
      " to 1.0011224746704102\n",
      " make 34.43307113647461\n",
      " a 3.528000593185425\n",
      " big 28.263988494873047\n",
      " shade 4077.759521484375\n",
      ". 10.71489143371582\n",
      " Then 9.587998390197754\n",
      " you 1.7063909769058228\n",
      " will 6.776829719543457\n",
      " be 1.7306737899780273\n",
      " cool 1.1418908834457397\n",
      " like 7.012413024902344\n",
      " the 3.8563337326049805\n",
      " other 1.081385850906372\n",
      " pump 1.0011353492736816\n",
      "kins 1.0003522634506226\n",
      ".\" 1.1834737062454224\n",
      " The 7.281824111938477\n",
      " pumpkin 1.0362809896469116\n",
      " was 1.3628908395767212\n",
      " happy 1.262645959854126\n",
      " to 9.166540145874023\n",
      " learn 1.350834608078003\n",
      " from 1.7863703966140747\n",
      " the 1.021977424621582\n",
      " bird 1.0019288063049316\n",
      ". 1.0512158870697021\n",
      " So 45.39388656616211\n",
      ", 1.0853655338287354\n",
      " they 2.4426159858703613\n",
      " worked 13.50831413269043\n",
      " together 1.0050323009490967\n",
      " to 1.3361650705337524\n",
      " make 1.0140527486801147\n",
      " a 1.4426571130752563\n",
      " big 1.2154605388641357\n",
      " shade 1.1918082237243652\n",
      " using 1431.189453125\n",
      " leaves 13.858613967895508\n",
      " and 1.1283425092697144\n",
      " sticks 2.219102144241333\n",
      ". 1.0491721630096436\n",
      "But 33144052.0\n",
      " then 7.098130702972412\n",
      ", 1.0127328634262085\n",
      " a 1.5494664907455444\n",
      " strong 13.308494567871094\n",
      " wind 1.010124683380127\n",
      " came 1.1321191787719727\n",
      " and 1.055877923965454\n",
      " blew 1.14146089553833\n",
      " the 1.4597468376159668\n",
      " shade 1.883432149887085\n",
      " away 1.0098401308059692\n",
      ". 1.0173782110214233\n",
      " The 1.0111439228057861\n",
      " pumpkin 1.0275721549987793\n",
      " was 1.2075257301330566\n",
      " sad 1.6013967990875244\n",
      " again 1.0198091268539429\n",
      ". 1.6373298168182373\n",
      " The 2.4631919860839844\n",
      " bird 1.03036630153656\n",
      " told 113.50904846191406\n",
      " the 1.0432045459747314\n",
      " pumpkin 1.0644010305404663\n",
      ", 1.1035938262939453\n",
      " \" 1.0000495910644531\n",
      "It 11.71666145324707\n",
      "'s 1.074927568435669\n",
      " okay 1.0747977495193481\n",
      ". 2.1145071983337402\n",
      " Sometimes 29.525537490844727\n",
      " things 1.4151908159255981\n",
      " don 1.389351487159729\n",
      "'t 1.0006005764007568\n",
      " work 3.7768054008483887\n",
      " out 1.2095762491226196\n",
      " the 1.4310650825500488\n",
      " way 1.0068010091781616\n",
      " we 1.0099643468856812\n",
      " want 1.0157761573791504\n",
      " them 1.085758924484253\n",
      " to 1.0008374452590942\n",
      ". 3.3343753814697266\n",
      " The 121.81158447265625\n",
      " important 1.436578631401062\n",
      " thing 1.0316047668457031\n",
      " is 1.0009280443191528\n",
      " to 1.0458972454071045\n",
      " keep 3.347849130630493\n",
      " trying 1.156503438949585\n",
      " and 1.8791544437408447\n",
      " never 2.766235828399658\n",
      " give 1.0035711526870728\n",
      " up 1.000026822090149\n",
      ".\" 1.1270099878311157\n",
      "The 88736.1875\n",
      " pumpkin 1.036982774734497\n",
      " learned 3.5599629878997803\n",
      " to 72.45037078857422\n",
      " be 4.95949649810791\n",
      " strong 14.126344680786133\n",
      " and 1.110846996307373\n",
      " keep 7.718044281005859\n",
      " trying 1.019019365310669\n",
      ", 1.1714810132980347\n",
      " even 1.1123754978179932\n",
      " when 1.108888030052185\n",
      " things 1.0048450231552124\n",
      " were 35.829261779785156\n",
      " hard 1.7358410358428955\n",
      ". 1.0078134536743164\n",
      " And 1.6010189056396484\n",
      " soon 27.387462615966797\n",
      ", 1.0365691184997559\n",
      " the 1.5350991487503052\n",
      " weather 8483.7509765625\n",
      " changed 18.810834884643555\n",
      ", 1.973299264907837\n",
      " and 1.0249110460281372\n",
      " the 1.2410469055175781\n",
      " pumpkin 1.0403599739074707\n",
      " was 1.4919121265411377\n",
      " cool 1.114590048789978\n",
      " and 27.747371673583984\n",
      " happy 1.0979762077331543\n",
      " like 109.5199203491211\n",
      " the 1.0717359781265259\n",
      " other 1.0523316860198975\n",
      " pump 1.0010946989059448\n",
      "kins 1.002062201499939\n",
      ". 1.2332282066345215\n",
      " The 27.4182071685791\n",
      " moral 2.6493453979492188\n",
      " of 1.1764813661575317\n",
      " the 1.0010207891464233\n",
      " story 1.0000231266021729\n",
      " is 1.0059661865234375\n",
      " to 1.1305755376815796\n",
      " never 1.0550752878189087\n",
      " give 1.0030266046524048\n",
      " up 1.0005764961242676\n",
      " and 2.8102848529815674\n",
      " keep 3.9929213523864746\n",
      " trying 1.0279030799865723\n",
      ", 1.2873530387878418\n",
      " even 1.1619610786437988\n",
      " when 1.192921757698059\n",
      " things 1.0074645280838013\n",
      " are 1.5431488752365112\n",
      " tough 8.022383689880371\n",
      ". 1.0180519819259644\n",
      "1.0180519819259644\n"
     ]
    }
   ],
   "source": [
    "# get token-level ppl of a random story\n",
    "token_ids, ppl = get_sentence_ppl(random_story, bos=True)\n",
    "token_ids = token_ids.cpu().numpy().tolist()[0]\n",
    "ppl = ppl.cpu().numpy().tolist()\n",
    "for token_id, ppl in zip(token_ids, ppl):\n",
    "    print(tokenizer.decode(token_id), ppl)\n",
    "print(np.mean(ppl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the tb and fb stories\n",
    "tb_stories = []\n",
    "fb_stories = []\n",
    "pos_tb_stories = []\n",
    "pos_fb_stories = []\n",
    "neg_tb_stories = []\n",
    "neg_fb_stories = []\n",
    "\n",
    "tb_cond_file  = f'../../data/conditions/tinytom-v3/0_forward_belief_true_belief/corrected.txt'\n",
    "fb_cond_file  = f'../../data/conditions/tinytom-v3/0_forward_belief_false_belief/corrected.txt'\n",
    "with open(tb_cond_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l, line in enumerate(lines):\n",
    "        tb_stories.append(line.strip())\n",
    "\n",
    "with open(fb_cond_file, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for l, line in enumerate(lines):        \n",
    "        fb_stories.append(line.strip())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once 3786918.75\n",
      " upon 1.0253037214279175\n",
      " a 1.0000678300857544\n",
      " time 1.0001612901687622\n",
      ", 1.0017625093460083\n",
      " in 26.137815475463867\n",
      " a 1.0432683229446411\n",
      " lovely 255.73524475097656\n",
      " park 147.6114044189453\n",
      " full 1578.48095703125\n",
      " of 1.004035472869873\n",
      " pretty 59.270225524902344\n",
      " flowers 1.1265602111816406\n",
      ", 6.635289192199707\n",
      " there 1.136163353919983\n",
      " was 1.290573239326477\n",
      " a 1.004797101020813\n",
      " little 1.7714539766311646\n",
      " girl 1.9726015329360962\n",
      " named 1.0066407918930054\n",
      " Queen 16705913.0\n",
      "ie 1.6073189973831177\n",
      ". 1.0317797660827637\n",
      " She 6.450061798095703\n",
      " needed 1701482.75\n",
      " a 11.8333740234375\n",
      " green 9422.484375\n",
      " leaf 5.010408401489258\n",
      " for 4.829154014587402\n",
      " her 1.0386905670166016\n",
      " art 878.48779296875\n",
      " project 2.2610509395599365\n",
      ". 1.047688364982605\n",
      " She 4.079145908355713\n",
      " spotted 51498.6015625\n",
      " a 1.6199395656585693\n",
      " leaf 25.733139038085938\n",
      " that 9.338224411010742\n",
      " was 1.553296446800232\n",
      " very 19.732328414916992\n",
      " green 13.203532218933105\n",
      " and 3.0927369594573975\n",
      " fresh 5605.99462890625\n",
      ". 1.009093999862671\n",
      " As 555.260009765625\n",
      " Queen 25.05815887451172\n",
      "ie 1.0032645463943481\n",
      " explored 3006647.0\n",
      " the 1.2598310708999634\n",
      " big 17194.716796875\n",
      " park 3.0037059783935547\n",
      ", 1.037485122680664\n",
      " the 482.73583984375\n",
      " sun 6.047307968139648\n",
      " smiled 368.815673828125\n",
      " brighter 89237.3125\n",
      " and 1.245975375175476\n",
      " brighter 5.542998313903809\n",
      ". 1.2051496505737305\n",
      " The 18.64461898803711\n",
      " little 36.90946578979492\n",
      " leaf 7.997826099395752\n",
      " got 1497.500244140625\n",
      " all 191.04339599609375\n",
      " warm 255.961181640625\n",
      " and 1.1251946687698364\n",
      " dry 4.424380302429199\n",
      " from 63.586273193359375\n",
      " the 1.073927402496338\n",
      " sun 1.566879391670227\n",
      "'s 6.843565940856934\n",
      " happy 63604.83984375\n",
      " heat 129.6708526611328\n",
      ". 1.0552184581756592\n",
      " Queen 1.0616527795791626\n",
      "ie 1.0021116733551025\n",
      " sees 112632016.0\n",
      " the 2.3846278190612793\n",
      " leaf 1.5700091123580933\n",
      " dried 403027.1875\n",
      " up 1.1155980825424194\n",
      " when 11445.033203125\n",
      " she 5.273295879364014\n",
      " returns 60749.78125\n",
      " to 3.9617679119110107\n",
      " it 230.74887084960938\n",
      ". 1.315391182899475\n",
      " Queen 13.292914390563965\n",
      "ie 1.0021352767944336\n",
      " believes 1626.76416015625\n",
      " the 14.61481761932373\n",
      " leaf 1.119633436203003\n",
      " is 5.029558181762695\n",
      "5.029558181762695\n"
     ]
    }
   ],
   "source": [
    "random_story = random.choice(tb_stories)\n",
    "token_ids, ppl = get_sentence_ppl(random_story, bos=True)\n",
    "token_ids = token_ids.cpu().numpy().tolist()[0]\n",
    "ppl = ppl.cpu().numpy().tolist()\n",
    "for token_id, ppl in zip(token_ids, ppl):\n",
    "    print(tokenizer.decode(token_id), ppl)\n",
    "print(np.mean(ppl))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "marple",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
